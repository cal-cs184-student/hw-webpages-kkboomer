<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
		<div style="text-align: center;">Names: Kellen Galban</div>

		<br>

		Link to webpage: (TODO) <a href="https://cal-cs184-student.github.io/hw-webpages-kkboomer/">https://cal-cs184-student.github.io/hw-webpages-kkboomer/</a>
		
		<br>

		Link to GitHub repository: (TODO) <a href="https://github.com/cal-cs184-student/hw1-rasterizer-aloharender" target="_blank">cs184.eecs.berkeley.edu/sp25</a>

		

		<!--
		We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		Over the past few weeks and 6 tasks I was able to implement a basic rasterizer that can take SVG files and accurately render them out
			using a variety of techniques. This rasterizer can perform basic super-sampling to help deal with aliasing up to 16x, perform barycentric interpolation, and use
			level and pixel sampling to map textures to surfaces at various antialiasing levels. I had a lot of fun getting back into C++ and
			seeing how to implement the high level mathematical concepts learned in class into code (though my git commit messages suggest there was some pain along the way :)).

			<h2>Task 1: Drawing Single-Color Triangles</h2>

			<p>Inside <code>RasterizerImp::rasterize_triangle</code> and given 3 points, we first reduce the area of the bounding box by finding the maximum and minimum x and y values from the points passed in.
				Then for each x and y position, we sample at the center of the pixel (an offset of 1/2 from the x or y position), then perform 3 half plane checks to see if the point is within the triangle.
				Since we need to be able to deal with either cw or ccw winding order, we check if all edge checks or either all \(<= 0\) or \(>= 0\), if either is true, we can be sure that the pixel is inside the triangle and we color it.
			</p>
			<p>
				Our algorithm still iterates over every pixel and sub-sample inside the triangle’s bounding box, just like a naïve implementation.
				The difference is that instead of recomputing edge functions from scratch for each sample, we incrementally update them using precomputed coefficients.
				This does not change the number of samples tested, so the asymptotic complexity remains the same, but it reduces the per-sample computation.
				Thus, the algorithm is no worse than checking each sample in the bounding box, and is strictly more efficient in practice.
			</p>
			<bold-text><i>basic/test4.svg</i></bold-text>
			<figure>
				<img src="write_up/task1_new.png" alt="basic/test4.svg" style="width:70%"/>
				<figcaption>Note how the thinner edges have severe aliasing and gaps</figcaption>
			</figure>
			<h3>EC optimizations</h3>
			<p>
				In terms of optimizations, previously I computed the edge tests for every point from scratch inside the loop,
				which especially when super-sampling came into the picture would slow down rendering. Since the edge checks are linear functions of the form \( Ax + By + C\), we can just increment the As and Bs as the loop progresses and cut out expensive multiplication calculations,
				I found that by and by only putting simple calculations inside the loops we cut down our computation and see the following gains. I did consider putting similar optimizations inside
				tasks 4 and 5/6. However, after encountering some funky artifacts that took too long to even diagnose, they were scrapped, which explains why super-sampling on test7.svg or anything in the texmap folder take much longer than anything in the basic folder.
				A future goal is to return to those functions and implement those optimizations.
			</p>
			<bold-text><i>Graph results</i></bold-text>
			<figure>
				<img src="write_up/graph.png" alt="basic/graph.svg" style="width:70%"/>
				<figcaption>A showcase of the effect of the optimization on basic rendering</figcaption>
			</figure>

			<h2>Task 2: Antialiasing by Supersampling</h2>

			<bold-text>How did we supersample? </bold-text> <br><br>
			<ol>
				<li>The main idea behind supersampling is to partition each individual pixel into smaller sections so that we can increase the sampling density, resulting in a more finer detail output.</li>
				<ul>
					<li>To draw the actual pixels on to the screen, a section of the rasterization pipeline includes resolving the sample buffer to the framebuffer.
						The sample buffer contains CGL Color data types; however, the framebuffer is an array of floats so "resolving" simply means converting the Color types into floats. </li>
					<li>When we supersample, we can increase or decrease the sampling rate. To accomodate the sampling rate change, we have to modify a couple of places. First, we have to adjust the size of the sample_buffer depending on the sampling rate. In <code>RasterizerImp::set_sample_rate</code> we resize the sample buffer to <code>sample_rate * width * height</code>. We do the same in <code>RasterizerImp::set_framebuffer_target</code>.</li>
					<li>In our main rasterization logic in <code>RasterizerImp::rasterize_triangle</code>, we multiply our loop start and end bounds by <code>sqrt(sample_rate)</code> to increase/decrease the density of the grid. To calculate the new coordinate of the sample point, we need to additionally find the inner offset of supersample pixel in relation to the main coordinate before we supersampled.</li>
					<ul>
						<li>Pixel coordinate (without supersample offset): \((\frac{x}{\sqrt{sample\_rate}}, \frac{y}{\sqrt{sample\_rate}})\)</li>
						<li>Supersample offset: \((x \bmod \sqrt{sample\_rate}, y \bmod \sqrt{sample\_rate}) \)</li>
					</ul>
					<ul>Putting it all together, our supersample pixel coordinate would is \((pixel\_x + \frac{(ss\_offset\_x + 0.5f)}{\sqrt{sample\_rate}}, pixel\_y + \frac{(ss\_offset\_y + 0.5f)}{\sqrt{sample\_rate}})\)</ul>
					<ul>To set the correct index in the sample buffer, the updated index is \((y * width + x) * sample\_rate + ss\_offset\_y * \sqrt{sample\_rate} + ss_offset_x\) </ul>
				</ul>
				<li>Modifying <code>RasterizerImp::fill_pixel</code>:</li>
				<ul>
					<li>For a pixel, we need to fill in all of the supersampled pixels to fix points and lines as we don't really care about supersampling for them. So within this function, we just fill the supersample pixels the same color.</li>
				</ul>
				<li>Averaging pixels in <code>RasterizerImp::resolve_to_framebuffer</code>:</li>
				<ul>
					<li>The final step of super-sampling is to average the neighboring pixels and set it back to the main pixel. In <code>RasterizerImp::resolve_to_framebuffer</code>, we are taking the average color rgb values from all the supersampled pixels of area \(sample\_rate\) to set it to the pixel in the framebuffer representing all of the supersampled pixels.</li>
				</ul>
			</ol>

			<bold-text><i>basic/test4.svg super-sampling rate comparisons:</i></bold-text>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="write_up/task2_1.png" width="400px"/>
							<figcaption>sampling rate 1 per pixel</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="write_up/task2_4.png" width="400px"/>
							<figcaption>sampling rate 4 per pixel</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="write_up/task2_16.png" width="400px"/>
							<figcaption>sampling rate 16 per pixel</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<br>
			<bold-text><i>Explanation of results:</i></bold-text>
			<p>
				As we increase the sampling rate, the edges of the triangles become smoother and less jagged, with the difference being more apparent on thinner edges. 
				This is because with a higher sampling rate and the modifications to <code>RasterizerImp::resolve_to_framebuffer</code>, the averaging of neighboring pixels helps to "fill" in the gaps that would otherwise be present when sampling at a lower rate, 
				resulting in smoother edges and a more accurate representation of the original triangle.
				When we sample at 1 per pixel, we are essentially taking a single point to represent the entire pixel, which can lead to jagged edges and gaps in the rendering. As we increase the sampling rate, we are able to capture more of the details of the triangle's edges, resulting in smoother and more accurate rendering.
			</p>
			<p>We can see that as the sampling rate per pixel increases, the averaging of neighboring pixels becomes more apparent. When we sample 1 per pixel, there are missing gaps and artifacts as a result of this aliasing.
				As we increase the sampling rate, the averaging step that we perform in <code>RasterizerImp::resolve_to_framebuffer</code> helps "fill" in the gap to provide a more smooth edge so that it looks more continuous.
				Since we are subdividing a pixel into more squares, when we average it acts like a <b>low pass filter</b> so that the averaged pixel smooths out sharp discontinuities and reduces high frequencies.
			</p>

			<h2>Task 3: Transforms </h2>

			<figure>
				<img src="write_up/task3.png" style="width:70%"/>
				<figcaption>K-Robot</figcaption>
			</figure>

			<bold-text> What is being done to the robot </bold-text> <br><br>
			<p>
				I performed a simple transformation by rotating every limb except the left leg to form a k shape with
				the robot. Since some of the rotation points are not at the points where the limbs are closest to the
				torso, I had to perform slight translations to get the limbs to line back up with the body.
			</p>
			<h2>Task 4: Barycentric coordinates</h2>

			<bold-text>What is a barycentric coordinate? </bold-text> <br><br>
			<p>
				Barycentric coords are a way of checking if a point is inside the triangle using its distance from a vertex.
				The weights alpha, beta, and gamma must sum to 1 and tell us how much that vertex affected the point.
				If all weights are non-negative, the point is inside the triangle and the pixel's color is determined by a
				weighted sum of alpha, beta, and gamma multiplied against each of the 3 colors we are interpolating.
				In the provided example, the vertexes are red, green and blue, and the color is determined by which of the vertices
				the point is closer to, one closer to the blue vertex is more blue,
				while one in the middle, with alpha, beta, and gamma being nearly equal, is mix of all 3 colors.
			</p>
			<figure>
				<img src="write_up/task4_aid.png" style="width:70%"/>
				<figcaption>A triangle with red, green, and blue vertices that when using barycentric
					interpolation the blending of colors is apparent.</figcaption>
			</figure>
			<figure>
				<img src="write_up/task4.png" style="width:70%"/>
				<figcaption>Color wheel, which is a bunch of RGB vertex triangles in a circular pattern</figcaption>
			</figure>
			<h2>Task 5: “Pixel sampling” for texture mapping</h2>

			<p>
				Pixel sampling is how we determine the color of a pixel when using continuous textures onto a discrete screen of pixels.
				To implement this, I march over each pixel in the bounding box, calculate its barycentric coordinates.
				If the point is inside the triangle, we interpolate the uv coordinates, which are then mapped to the
				texture space and sampled according to the chosen sampling method.
			</p>

			<p>
				In nearest sampling, we select the closest texel (the smallest unit that makes up the texture), and take that color,
				but this produces sharp and blocky results, which can look bad far away.
				In bilinear sampling, we do a similar process to supersampling in which we interpolate between 4 surrounding texels,
				and calculate a weight sum based on the fractional change in the x and y directions which produces a smoother final product.
			</p>

			<p>
				I used texmap/test1.svg for all 4 screenshots
			</p>

			<bold-text><i>Nearest Neighbor Sampling 1 sample per px </i></bold-text>
			<figure>
				<img src="write_up/task5_n1.png" style="width:70%"/>
				<figcaption></figcaption>
			</figure>

			<bold-text><i>Bilinear Sampling 1 sample per px </i></bold-text>
			<figure>
				<img src="write_up/task5_b1.png"  style="width:70%"/>
				<figcaption></figcaption>
			</figure>

			<bold-text><i>Nearest Neighbor Sampling 16 sample per px </i></bold-text>
			<figure>
				<img src="write_up/task5_n16.png" style="width:70%"/>
				<figcaption></figcaption>
			</figure>

			<bold-text><i>Bilinear Sampling 16 sample per px </i></bold-text>
			<figure>
				<img src="write_up/task5_b16.png" style="width:70%"/>
				<figcaption></figcaption>
			</figure>

			<bold-text>Comment on the relative differences. Discuss when there will be a large difference between
				the two methods and why.
			</bold-text> <br><br>

			<p>
				While at a glance nearest can be distinguished from bilinear thanks to its blockiness, the difference is amplified when textures are magnified or have detail at high frequency,
				since bilinear will smooth out that higher frequency detail to reduce aliasing while nearest will allow pixelated rendering.
			</p>

			<h2>Task 6: “Level sampling” with mipmaps for texture mapping</h2>

			<p>
				Level sampling determines which quality of a texture (aka mipmap level) should be used when sampling a texture for a pixel. 
				It solves the problem of a texture when viewed from far away and having the highest quality texture, many pixels corresponding to large regions causing aliasing. 
				By choosing a lower resolution version of the texture, we can better match how much texture is being compressed, reducing Moiré patterns and other aliasing artifacts. 
				I implemented this very similarly to the previous tasks. At every pixel in the bounding box, we compute the barycentric coordinates, and if it is within the region that is to be textured, we estimate the uv derivatives in the x and y directions which will help estimate the level of detail, then create a <code>SampleParams</code> struct to store our data, vectors, and  pixel/level sampling methods. 
				From there we call the <code>sample()</code> method to get the color. During this function call, if the lsm is either L_ZERO (mipmap level 0) or L_NEAREST (nearest mip level rounded down), we do a similar call to the corresponding method for nearest or bilinear pixel sampling. 
				Otherwise, we perform a linear interpolation. We decide the 2 colors we will be linearly interpolating between based on the pixel sampling method chosen using this equation: \(c_0 * (1 - t) + c_1 * t\), where c_0 and c_1 are the colors at the current level rounded down 
				and 1 level up respectively, and the float t is the current level minus c_0. This produces a much smoother transition between the mip levels and reduces artifacts.
			</p>
			<bold-text>Some of the differences between the three sampling methods:</bold-text> <br><br>
			<ol>
				<li><bold-text>Pixel Sampling</bold-text></li>
				<p>
					This method is one of the faster methods, especially in NEAREST mode since it is only 1 lookup. With LINEAR mode it gets a bit slower
					since we are performing 4 lookups and doing a weighted average, but it is still pretty fast. Both modes do not use extra memory we just use the original pixels to do our sampling.
					This method is not the best at antialiasing as aliased lines will still appear to be blocky and may still contain artifacts, especially when the texture is minified.
				<li><bold-text>Level Sampling</bold-text></li>
				<p>
					Level sampling is a bit slower than pixel sampling since we have to perform calculations to find the appropriate mipmap level, 
					but it is still faster than number of samples per pixel since we are not performing multiple lookups for each pixel.
					We have to use more memory to store the mipmap texture, but it is worth it since it can prevent texture minification and moiré patterns.
				</p>
				<li><bold-text>Number Of Samples Per Pixel (aka supersampling)</bold-text></li>
				<p>This method is the slowest due to the time taken to compute each sample increases linearlry with the sample rate. 
					It also uses more memory than per pixel sampling since we increase the size of our sample buffer linearly with the sample number. 
					However, it has the best antialiasing power as it can help smooth out jagged edges and other artifacts by averaging neighboring pixels together.</p>
				</p>
			</ol>

			<bold-text><i>Image of the a tile shown with differing lsm/psm combinations:</i></bold-text>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="write_up/task6_0n.png" width="400px"/>
							<figcaption>L_ZERO, P_NEAREST</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="write_up/task6_0b.png" width="400px"/>
							<figcaption>L_ZERO, P_LINEAR</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="write_up/task6_nn.png" width="400px"/>
							<figcaption>L_NEAREST, P_NEAREST</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="write_up/task6_nb.png" width="400px"/>
							<figcaption>L_NEAREST, P_LINEAR</figcaption>
						</td>
					</tr>
				</table>
			</div>
		</div>
	</body>
</html>